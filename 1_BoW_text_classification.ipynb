{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KthJSHkGQR7Z"
   },
   "source": [
    "# Bag of Words Text Classification\n",
    "\n",
    "In this tutorial we will show how to build a simple Bag of Words (BoW) text classifier using PyTorch. The classifier is trained on IMDB movie reviews dataset. \n",
    "\n",
    "\n",
    "## Concepts covered in this tutorial\n",
    "1. NLP text pre-processing\n",
    "2. Split of training, validation and testing datasets\n",
    "3. How to build a simple feed-forward neural net classifier using PyTorch \n",
    "4. Training the model and the balance of Under-fitting v.s. Over-fitting\n",
    "5. BoW and TF-IDF text classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "colab_type": "code",
    "id": "ZniLdSpeQR7l",
    "outputId": "93479c0a-a275-4cc8-d8ee-5729a31346e7"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "_8cUAJPMQR7g",
    "outputId": "6bbc704a-a991-44f4-fec8-139e9959f31d"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import re # regular expression\n",
    "from collections import Counter \n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from google_drive_downloader import GoogleDriveDownloader as gdd\n",
    "from IPython.core.display import display, HTML\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer # TF-IDF\n",
    "from sklearn.metrics import classification_report\n",
    "from tqdm import tqdm, tqdm_notebook # show progress bar\n",
    "\n",
    "# PyTorch modules\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.dataset import random_split\n",
    "\n",
    "# nltk text processors\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import wordpunct_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_formats = ['svg']\n",
    "plt.style.use('ggplot')\n",
    "tqdm.pandas()\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j8-WlORVQR7n"
   },
   "outputs": [],
   "source": [
    "DATA_PATH = 'data/imdb_reviews.csv'\n",
    "if not Path(DATA_PATH).is_file():\n",
    "    gdd.download_file_from_google_drive(\n",
    "        file_id='1zfM5E6HvKIe7f3rEt1V2gBpw5QOSSKQz',\n",
    "        dest_path=DATA_PATH,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YJmd3NNtQR7s"
   },
   "source": [
    "**Take a look at a few examples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "colab_type": "code",
    "id": "FnsKvqrXQR7t",
    "outputId": "d1c2a242-7262-480f-c317-67088eb5a9de"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(DATA_PATH)\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 228
    },
    "colab_type": "code",
    "id": "oTM2IdHRQR7y",
    "outputId": "18eb9a56-ac06-45f4-c02f-2ecc94f5d60d"
   },
   "outputs": [],
   "source": [
    "print('Number of records:', len(df), '\\n')\n",
    "print('Number of positive reviews:', len(df[df.label == 1]))\n",
    "print('Number of negative reviews:', len(df[df.label == 0]), '\\n')\n",
    "\n",
    "print('Example negative review:')\n",
    "print(df.loc[55,].review, '\\n')\n",
    "print('Example positive review:')\n",
    "print(df.loc[12361,].review, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kajOXwKjQR71"
   },
   "source": [
    "## Preprocess Text\n",
    "\n",
    "* Replace weird characters\n",
    "* Lowercase\n",
    "* Tokenize \n",
    "* Stemming & Lemmatize\n",
    "* Remove stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NEAMiSRUQR71"
   },
   "source": [
    "**Let's see how to pre-process these steps one by one. Below I constructed a test corpus which composed of 3 reviews. Each review is a paragraph.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "bd4I86AdQR72",
    "outputId": "aeb9f8cf-05f8-4997-8f35-c9b06bdcd0f7"
   },
   "outputs": [],
   "source": [
    "test_corpus = '''The Intel Core i5 processor that comes with the Dell Latitude 5490 is quad-core and offers 1.6GHz and a 6M cache. The base configuration includes 1 x 4GB of DDR4 Non-CC memory, but this can be upgraded to 8GB or even 16GB (2 x 8GB) if you require more memory. How great is that!?\n",
    "The 14-inch display is available with your choice of 1366 x 768 or 1920 x 1080 resolution. Both versions are non-touch, WLAN capable, and come with anti-glare technology. You also get a built-in camera and microphone. For wireless technology, the system comes with a Qualcomm QCA61 x 4A 802.11 ac (2Ã—2) wireless adapter+.\n",
    "'''\n",
    "test_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "__qLl57RQR74",
    "outputId": "90fbff97-ca94-4306-9e3a-047b02320ee9"
   },
   "outputs": [],
   "source": [
    "# remove special characters & lowercase\n",
    "clean_corpus = re.sub(r'[^\\w\\s]', '', test_corpus)\n",
    "clean_corpus = clean_corpus.lower()\n",
    "clean_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "wEXzzABQQR78",
    "outputId": "78367840-edc7-4248-e21c-6d535b0bea1f"
   },
   "outputs": [],
   "source": [
    "# tokenize\n",
    "clean_tokens = wordpunct_tokenize(clean_corpus)\n",
    "print(clean_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "yiNcDaSdQR7_",
    "outputId": "abfc628a-4282-4d75-b3c2-88816101b376"
   },
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "clean_tokens = [lemmatizer.lemmatize(token) for token in clean_tokens]\n",
    "clean_tokens = [lemmatizer.lemmatize(token, \"v\") for token in clean_tokens]\n",
    "print(clean_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "--w6TAk1QR8E",
    "outputId": "3ff2f92b-4385-403e-b8bd-b08ca04b10db"
   },
   "outputs": [],
   "source": [
    "clean_tokens = [re.sub(r'\\b[0-9]+\\b', '<NUM>', token) for token in clean_tokens]\n",
    "print(clean_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "h7PBL2lIQR8I",
    "outputId": "49e113ac-a018-4e05-bf98-67c122cdfbe3"
   },
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "clean_tokens = [token for token in clean_tokens if token not in stop_words]\n",
    "print(clean_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "9t4Mc4pxQR8P",
    "outputId": "d90240a4-545f-4b90-eb83-75bd9742848e"
   },
   "outputs": [],
   "source": [
    "def build_vocab(corpus):\n",
    "    vocab = {}\n",
    "    for doc in corpus:\n",
    "        for token in doc:\n",
    "            if token not in vocab.keys():\n",
    "                vocab[token] = len(vocab)\n",
    "    return vocab\n",
    "\n",
    "print(build_vocab([clean_tokens]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "rQw7-4YFQR8S",
    "outputId": "b7b9c147-43ff-4951-f430-0c3d7b6c9b00"
   },
   "outputs": [],
   "source": [
    "def build_index2token(vocab):\n",
    "    index2token = {}\n",
    "    for token in vocab.keys():\n",
    "        index2token[vocab[token]] = token\n",
    "    return index2token\n",
    "\n",
    "print(build_index2token(build_vocab([clean_tokens])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sOAIqMzqBXiv"
   },
   "source": [
    "**Bag of Words** \n",
    "\n",
    "\n",
    "\n",
    "**TF-IDF**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jCw9LKDKQR8W"
   },
   "source": [
    "**Let's pacakage the pre-processing steps together into functions and apply on our dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GHCoa8R_QR8W"
   },
   "outputs": [],
   "source": [
    "def remove_rare_words(tokens, common_tokens, max_len):\n",
    "    return [token if token in common_tokens else '<UNK>' for token in tokens][-max_len:]\n",
    "\n",
    "def replace_numbers(tokens):\n",
    "    return [re.sub(r'[0-9]+', '<NUM>', token) for token in tokens]\n",
    "\n",
    "def tokenize(text, stop_words, lemmatizer):\n",
    "    text = re.sub(r'[^\\w\\s]', '', text) # remove special characters\n",
    "    text = text.lower() # lowercase\n",
    "    tokens = wordpunct_tokenize(text) # tokenize\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens] # noun lemmatizer\n",
    "    tokens = [lemmatizer.lemmatize(token, \"v\") for token in tokens] # verb lemmatizer\n",
    "    tokens = [token for token in tokens if token not in stop_words] # remove stopwords\n",
    "    return tokens\n",
    "\n",
    "def build_bow_vector(sequence, idx2token):\n",
    "    vector = [0] * len(idx2token)\n",
    "    for token_idx in sequence:\n",
    "        if token_idx not in idx2token:\n",
    "            raise ValueError('Wrong sequence index found!')\n",
    "        else:\n",
    "            vector[token_idx] += 1\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bYb2RZSI_F8A"
   },
   "outputs": [],
   "source": [
    "# Set parameters\n",
    "\n",
    "MAX_LEN = 128 #@param [64, 256, 512, 1024] {allow-input: true}\n",
    "MAX_VOCAB = 1000 #@param [1000, 5000, 10000, 100000] {allow-input: true}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cRpfCXB5QR8Y"
   },
   "outputs": [],
   "source": [
    "class ImdbDataset(Dataset):\n",
    "    def __init__(self, data_path, max_vocab=5000, max_len=128):\n",
    "        df = pd.read_csv(data_path)\n",
    "        \n",
    "        # Clean and tokenize\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        df['tokens'] = df.review.apply(\n",
    "            partial(\n",
    "                tokenize,\n",
    "                stop_words=stop_words,\n",
    "                lemmatizer=lemmatizer,\n",
    "            ),\n",
    "        )  \n",
    "        \n",
    "        all_tokens = [token for doc in list(df.tokens) for token in doc]\n",
    "        \n",
    "        # Build most common tokens bound by max vocab size\n",
    "        common_tokens = set( \n",
    "            list(\n",
    "                zip(*Counter(all_tokens).most_common(max_vocab))\n",
    "            )[0] \n",
    "        )\n",
    "        \n",
    "        # Replace rare words with <UNK>\n",
    "        df.loc[:, 'tokens'] = df.tokens.progress_apply(\n",
    "            partial(\n",
    "                remove_rare_words,\n",
    "                common_tokens=common_tokens,\n",
    "                max_len=max_len,\n",
    "            ),\n",
    "        )\n",
    "        \n",
    "        # Replace numbers with <NUM>\n",
    "        df.loc[:, 'tokens'] = df.tokens.progress_apply(replace_numbers)\n",
    "        \n",
    "        # Remove sequences with only <UNK>\n",
    "        df = df[df.tokens.progress_apply(\n",
    "            lambda tokens: any(token != '<UNK>' for token in tokens),\n",
    "        )]\n",
    "        \n",
    "        # Build vocab\n",
    "        vocab = sorted(set(\n",
    "            token for doc in list(df.tokens) for token in doc\n",
    "        ))\n",
    "        self.token2idx = {token: idx for idx, token in enumerate(vocab)}\n",
    "        self.idx2token = {idx: token for token, idx in self.token2idx.items()}\n",
    "        \n",
    "        # Convert tokens to indexes\n",
    "        df['indexed_tokens'] = df.tokens.progress_apply(\n",
    "            lambda doc: [self.token2idx[token] for token in doc],\n",
    "        )\n",
    "        \n",
    "        # Build BoW vector\n",
    "        df['bow_vector'] = df.indexed_tokens.progress_apply(\n",
    "            build_bow_vector, args=(self.idx2token,)\n",
    "        )\n",
    "        \n",
    "        # Build TF-IDF vector\n",
    "        vectorizer = TfidfVectorizer(\n",
    "            analyzer='word',\n",
    "            tokenizer=lambda doc: doc,\n",
    "            preprocessor=lambda doc: doc,\n",
    "            token_pattern=None,\n",
    "        )\n",
    "        vectors = vectorizer.fit_transform(df.tokens).toarray()\n",
    "        df['tfidf_vector'] = [vector.tolist() for vector in vectors]\n",
    "        \n",
    "        self.text = df.review.tolist()\n",
    "        self.sequences = df.indexed_tokens.tolist()\n",
    "        self.bow_vector = df.bow_vector.tolist()\n",
    "        self.tfidf_vector = df.tfidf_vector.tolist()\n",
    "        self.targets = df.label.tolist()\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        return (\n",
    "            self.sequences[i],\n",
    "            self.bow_vector[i],\n",
    "            self.tfidf_vector[i],\n",
    "            self.targets[i],\n",
    "            self.text[i],\n",
    "        )\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "colab_type": "code",
    "id": "K31nmR1KQR8a",
    "outputId": "f66313c7-db9f-40c1-cacb-f440eab6dd84"
   },
   "outputs": [],
   "source": [
    "dataset = ImdbDataset(DATA_PATH, max_vocab=MAX_VOCAB, max_len=MAX_LEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZgCt9GdyQR8d"
   },
   "source": [
    "See a random sample out of the dataset processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 280
    },
    "colab_type": "code",
    "id": "V57qJlwuQR8e",
    "outputId": "1442a381-1798-4401-a341-821287ee71b2"
   },
   "outputs": [],
   "source": [
    "print('Number of records:', len(dataset), '\\n')\n",
    "\n",
    "import random\n",
    "random_idx = random.randint(0,len(dataset)-1)\n",
    "print('index:', random_idx, '\\n')\n",
    "sample_seq, bow_vector, tfidf_vector, sample_target, sample_text = dataset[random_idx]\n",
    "print(sample_text, '\\n')\n",
    "print(sample_seq, '\\n')\n",
    "print('BoW vector size:', len(bow_vector), '\\n')\n",
    "print('TF-IDF vector size:', len(tfidf_vector), '\\n')\n",
    "print('Sentiment:', sample_target, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3ScUh32jQR8g"
   },
   "source": [
    "## Split into training, validation, and test sets\n",
    "\n",
    "- **Training**: data the model learns from\n",
    "- **Validation**: data to evaluate with for hyperparameter tuning (make sure the model doesn't overfit!)\n",
    "- **Testing**: data to evaluate the final performance of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n06g-zwTQR8g"
   },
   "outputs": [],
   "source": [
    "def split_train_valid_test(corpus, valid_ratio=0.1, test_ratio=0.1):\n",
    "    \"\"\"Split dataset into train, validation, and test.\"\"\"\n",
    "    test_length = int(len(corpus) * test_ratio)\n",
    "    valid_length = int(len(corpus) * valid_ratio)\n",
    "    train_length = len(corpus) - valid_length - test_length\n",
    "    return random_split(\n",
    "        corpus, lengths=[train_length, valid_length, test_length],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "qRIrAPkmQR8i",
    "outputId": "8a2b6f1c-ab05-4640-82ee-cc95ac397b86"
   },
   "outputs": [],
   "source": [
    "train_dataset, valid_dataset, test_dataset = split_train_valid_test(\n",
    "    dataset, valid_ratio=0.05, test_ratio=0.05)\n",
    "len(train_dataset), len(valid_dataset), len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z1iPjOIOQR8l"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 528\n",
    "\n",
    "def collate(batch):\n",
    "    seq = [item[0] for item in batch]\n",
    "    bow = [item[1] for item in batch]\n",
    "    tfidf = [item[2] for item in batch]\n",
    "    target = torch.LongTensor([item[3] for item in batch])\n",
    "    text = [item[4] for item in batch]\n",
    "    return seq, bow, tfidf, target, text\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, collate_fn=collate)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, collate_fn=collate)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, collate_fn=collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 245
    },
    "colab_type": "code",
    "id": "3LNYX9TOQR8n",
    "outputId": "143d7d6a-512b-4f4c-a563-36b3d96cd392"
   },
   "outputs": [],
   "source": [
    "print('number of training batches:', len(train_loader), '\\n')\n",
    "batch_idx = random.randint(0, len(train_loader)-1)\n",
    "example_idx = random.randint(0, BATCH_SIZE-1)\n",
    "\n",
    "for i, fields in enumerate(train_loader):\n",
    "    seq, bow, tfidf, target, text = fields\n",
    "    if i == batch_idx:\n",
    "        print('Training input sequence:', seq[example_idx], '\\n')\n",
    "        print('BoW vector size:', len(bow[example_idx]), '\\n')\n",
    "        print('TF-IDF vector size:', len(tfidf[example_idx]), '\\n')\n",
    "        print('Label: ', target[example_idx], '\\n')\n",
    "        print('Review text:', text[example_idx], '\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dRziGFdtQR8p"
   },
   "source": [
    "## BoW Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1aZ_jCUBGll4"
   },
   "source": [
    "### Build BoW Model\n",
    "\n",
    "![BOW](https://github.com/scoutbeedev/pytorch-nlp-notebooks/blob/master/images/bow_representation.png?raw=1)\n",
    "\n",
    "- Input: BoW Vector\n",
    "- Model: \n",
    "    - feed-forward fully connected network\n",
    "    - 2 hidden layers\n",
    "- Output: \n",
    "    - vector size of 2 (2 possible outcome: positive v.s. negative)\n",
    "    - probability of input document classified as the label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-eKgEFZOQR8s"
   },
   "outputs": [],
   "source": [
    "class FeedfowardTextClassifier(nn.Module):\n",
    "    def __init__(self, device, vocab_size, hidden1, hidden2, num_labels, batch_size):\n",
    "        super(FeedfowardTextClassifier, self).__init__()\n",
    "        self.device = device\n",
    "        self.batch_size = batch_size\n",
    "        self.fc1 = nn.Linear(vocab_size, hidden1)\n",
    "        self.fc2 = nn.Linear(hidden1, hidden2)\n",
    "        self.fc3 = nn.Linear(hidden2, num_labels)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        batch_size = len(x)\n",
    "        if batch_size != self.batch_size:\n",
    "            self.batch_size = batch_size\n",
    "        x = torch.FloatTensor(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return torch.sigmoid(self.fc3(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EgoFy6Z3K5vC"
   },
   "outputs": [],
   "source": [
    "# Define hidden layer size\n",
    "HIDDEN1 = 100 #@param [10, 30, 50, 100, 200, 500] {allow-input: true}\n",
    "HIDDEN2 = 50 #@param [10, 30, 50, 100, 200, 500] {allow-input: true}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oJHJnPnJLUfo"
   },
   "source": [
    "P.S. You can also add layers or reduce layers by modifying the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "M0Q9ze4EQR8t",
    "outputId": "54fd71a7-c105-4ce4-a016-949dccfa0947"
   },
   "outputs": [],
   "source": [
    "bow_model = FeedfowardTextClassifier(\n",
    "    vocab_size=len(dataset.token2idx),\n",
    "    hidden1=HIDDEN1,\n",
    "    hidden2=HIDDEN2,\n",
    "    num_labels=2,\n",
    "    device=device,\n",
    "    batch_size=BATCH_SIZE,\n",
    ")\n",
    "bow_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "a3PifawkQR8w",
    "outputId": "0be52dc1-87e1-44db-cd59-6aaa306603a1"
   },
   "outputs": [],
   "source": [
    "for param in bow_model.parameters():\n",
    "    print(param.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F9AG4SosQR80"
   },
   "source": [
    "### Train BoW Model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Layer 1 affine: $$x_1 = W_1 X + b_1$$\n",
    "Layer 1 activation: $$h_1 = Relu(x_1)$$\n",
    "Layer 2 affine: $$x_2 = W_2 h_1 + b_2$$\n",
    "output: $$p = softmax(x_2)$$\n",
    "Loss: $$L = âˆ’(ylog(p)+(1âˆ’y)log(1âˆ’p))$$\n",
    "Gradient: \n",
    "$$\\frac{\\partial }{\\partial W_1}L(W_1, b_1, W_2, b_2) = \\frac{\\partial L}{\\partial p}\\frac{\\partial p}{\\partial x_2}\\frac{\\partial x_2}{\\partial h_1}\\frac{\\partial h_1}{\\partial x_1}\\frac{\\partial x_1}{\\partial W_1}$$\n",
    "\n",
    "Parameter update:\n",
    "$$W_1 = W_1 - \\alpha \\frac{\\partial L}{\\partial W_1}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FsGaRTbKGy2F"
   },
   "source": [
    "**Define the initial learning rate**\n",
    "\n",
    "What happens if you set a very small learning rate? What if you set a very large learning rate? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "58BGkAHOE8Lf"
   },
   "outputs": [],
   "source": [
    "LEARNING_RATE = 5e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3utDgyY2G2vK"
   },
   "source": [
    "**Define loss function and gradient descent optimizer**\n",
    "\n",
    "- Criterion: compute *Loss* to see how much does prediction differ from truth\n",
    "- Optimizer: different ways of updating the weight parameters. It can affect the speed of training and how easily are global minimum reached. \n",
    "- scheduler: dynamic alter the learning rate\n",
    "\n",
    "When selecting optimizers, you can think about what problems can we run into when performing gradient desent? (hint: global minimum v.s. local minimum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H2emTYNqE4yC"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(\n",
    "    filter(lambda p: p.requires_grad, bow_model.parameters()),\n",
    "    lr=LEARNING_RATE,\n",
    ")\n",
    "scheduler = CosineAnnealingLR(optimizer, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IpHbURwPH74N"
   },
   "source": [
    "**Define training round & validation round**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ROAha1KQQR81"
   },
   "outputs": [],
   "source": [
    "def train_epoch(model, optimizer, train_loader, input_type='bow'):\n",
    "    model.train()\n",
    "    total_loss, total = 0, 0\n",
    "    for seq, bow, tfidf, target, text in train_loader:\n",
    "        if input_type == 'bow':\n",
    "            inputs = bow\n",
    "        if input_type == 'tfidf':\n",
    "            inputs = tfidf\n",
    "        \n",
    "        # Reset gradient\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        output = model(inputs)\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = criterion(output, target)\n",
    "        \n",
    "        # Perform gradient descent, backwards pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Take a step in the right direction\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        # Record metrics\n",
    "        total_loss += loss.item()\n",
    "        total += len(target)\n",
    "\n",
    "    return total_loss / total\n",
    "\n",
    "\n",
    "def validate_epoch(model, valid_loader, input_type='bow'):\n",
    "    model.eval()\n",
    "    total_loss, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for seq, bow, tfidf, target, text in valid_loader:\n",
    "            if input_type == 'bow':\n",
    "                inputs = bow\n",
    "            if input_type == 'tfidf':\n",
    "                inputs = tfidf\n",
    "\n",
    "            # Forward pass\n",
    "            output = model(inputs)\n",
    "\n",
    "            # Calculate how wrong the model is\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            # Record metrics\n",
    "            total_loss += loss.item()\n",
    "            total += len(target)\n",
    "\n",
    "    return total_loss / total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4JwqTT6bQR83"
   },
   "source": [
    "** Run training epochs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "k_DOlOHkQR83",
    "outputId": "003994fa-f5dc-482a-a3e3-e38d4816f2db"
   },
   "outputs": [],
   "source": [
    "n_epochs = 0\n",
    "train_losses, valid_losses = [], []\n",
    "while True:\n",
    "    train_loss = train_epoch(bow_model, optimizer, train_loader, input_type='bow')\n",
    "    valid_loss = validate_epoch(bow_model, valid_loader, input_type='bow')\n",
    "    \n",
    "    tqdm.write(\n",
    "        f'epoch #{n_epochs + 1:3d}\\ttrain_loss: {train_loss:.2e}\\tvalid_loss: {valid_loss:.2e}\\n',\n",
    "    )\n",
    "    \n",
    "    # Early stopping if the current valid_loss is greater than the last three valid losses\n",
    "    if len(valid_losses) > 2 and all(valid_loss >= loss for loss in valid_losses[-3:]):\n",
    "        print('Stopping early')\n",
    "        break\n",
    "    \n",
    "    train_losses.append(train_loss)\n",
    "    valid_losses.append(valid_loss)\n",
    "    \n",
    "    n_epochs += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "kmGeqkhPZ9cp",
    "outputId": "1dc2648a-bdd1-4c42-e9dd-9b52fc2e90c3"
   },
   "outputs": [],
   "source": [
    "epoch_ticks = range(1, n_epochs + 1)\n",
    "plt.plot(epoch_ticks, train_losses)\n",
    "plt.plot(epoch_ticks, valid_losses)\n",
    "plt.legend(['Train Loss', 'Valid Loss'])\n",
    "plt.title('Losses') \n",
    "plt.xlabel('Epoch #')\n",
    "plt.ylabel('Loss')\n",
    "plt.xticks(epoch_ticks)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0hmGZdPhGUyO"
   },
   "source": [
    "### Check Performance of BoW Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "oyUgARIFGRtQ",
    "outputId": "e6baad84-5ab4-4315-dfd4-631df90188cf"
   },
   "outputs": [],
   "source": [
    "bow_model.eval()\n",
    "test_accuracy, n_examples = 0, 0\n",
    "y_true, y_pred = [], []\n",
    "input_type = 'bow'\n",
    "\n",
    "with torch.no_grad():\n",
    "    for seq, bow, tfidf, target, text in test_loader:\n",
    "        inputs = bow\n",
    "        probs = bow_model(inputs)\n",
    "        if input_type == 'tdidf':\n",
    "            inputs = tfidf\n",
    "            probs = tfidf_model(inputs)\n",
    "        \n",
    "        probs = probs.detach().cpu().numpy()\n",
    "        predictions = np.argmax(probs, axis=1)\n",
    "        target = target.cpu().numpy()\n",
    "        \n",
    "        y_true.extend(predictions)\n",
    "        y_pred.extend(target)\n",
    "        \n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SdUah0AkIOdq"
   },
   "source": [
    "**Let's check a few examples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sr0faB2WIe-M"
   },
   "outputs": [],
   "source": [
    "flatten = lambda x: [sublst for lst in x for sublst in lst]\n",
    "seq_lst, bow_lst, tfidf_lst, target_lst, text_lst = zip(*test_loader)\n",
    "seq_lst, bow_lst, tfidf_lst, target_lst, text_lst = map(flatten, [seq_lst, bow_lst, tfidf_lst, target_lst, text_lst])\n",
    "test_examples = list(zip(seq_lst, bow_lst, tfidf_lst, target_lst, text_lst))\n",
    "\n",
    "def print_random_prediction(model, n=5, input_type='bow'):\n",
    "    to_emoji = lambda x: 'ðŸ˜„' if x else 'ðŸ˜¡'\n",
    "    model.eval()\n",
    "    rows = []\n",
    "    for i in range(n):\n",
    "        with torch.no_grad():\n",
    "            seq, bow, tdidf, target, text = random.choice(test_examples)\n",
    "            target = target.item()\n",
    "            \n",
    "            inputs = bow\n",
    "            if input_type == 'tdidf':\n",
    "                inputs = tfidf\n",
    "\n",
    "            probs = model([inputs])\n",
    "            probs = probs.detach().cpu().numpy()\n",
    "            prediction = np.argmax(probs, axis=1)[0]\n",
    "\n",
    "            predicted = to_emoji(prediction)\n",
    "            actual = to_emoji(target)\n",
    "            \n",
    "            row = f\"\"\"\n",
    "            <tr>\n",
    "            <td>{i+1}&nbsp;</td>\n",
    "            <td>{text}&nbsp;</td>\n",
    "            <td>{predicted}&nbsp;</td>\n",
    "            <td>{actual}&nbsp;</td>\n",
    "            </tr>\n",
    "            \"\"\"\n",
    "            rows.append(row)\n",
    "            \n",
    "    rows_joined = '\\n'.join(rows)\n",
    "    table = f\"\"\"\n",
    "    <table>\n",
    "    <tbody>\n",
    "    <tr>\n",
    "    <td><b>Number</b>&nbsp;</td>\n",
    "    <td><b>Review</b>&nbsp;</td>\n",
    "    <td><b>Predicted</b>&nbsp;</td>\n",
    "    <td><b>Actual</b>&nbsp;</td>\n",
    "    </tr>{rows_joined}\n",
    "    </tbody>\n",
    "    </table>\n",
    "    \"\"\"\n",
    "    display(HTML(table))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "HPZKONRaIu_U",
    "outputId": "62ae5344-cf90-402d-baf3-8913947c7acc"
   },
   "outputs": [],
   "source": [
    "print_random_prediction(bow_model, n=5, input_type='bow')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Evqnu98cQR86"
   },
   "source": [
    "## TF-IDF Model\n",
    "\n",
    "**Term Frequency - Inverse Document Frequency**\n",
    "\n",
    "For a term `i` in document `j`:\n",
    "\n",
    "$$TFIDF = TF_{i,j} \\times log \\frac{N}{DF_i}$$\n",
    "\n",
    "- TF: number of occurance of the term `i` in document `j`\n",
    "- N: total number of documents\n",
    "- DF: number of documents containins the term `i`\n",
    "\n",
    "Questions:\n",
    "- Why would this be more representative than pure bag of words? \n",
    "- What does TFIDF score of a word mean for a document?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PJJqesoYPheB"
   },
   "source": [
    "### Initialize TF-IDF Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d15zhDh1OTCp"
   },
   "outputs": [],
   "source": [
    "# Define hidden layer size\n",
    "HIDDEN1 = 100 #@param [10, 30, 50, 100, 200, 500] {allow-input: true}\n",
    "HIDDEN2 = 50 #@param [10, 30, 50, 100, 200, 500] {allow-input: true}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "colab_type": "code",
    "id": "e0kloodgQR87",
    "outputId": "bb7e75de-c70d-435c-c760-5bf65810b813"
   },
   "outputs": [],
   "source": [
    "tfidf_model = FeedfowardTextClassifier(\n",
    "    vocab_size=len(dataset.token2idx),\n",
    "    hidden1=HIDDEN1,\n",
    "    hidden2=HIDDEN2,\n",
    "    num_labels=2,\n",
    "    device=device,\n",
    "    batch_size=BATCH_SIZE,\n",
    ")\n",
    "tfidf_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7w-9q4ErPmiL"
   },
   "source": [
    "### Train TF-IDF Model\n",
    "\n",
    "TF-IDF vectors as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2vxcXt_-PX0X"
   },
   "outputs": [],
   "source": [
    "LEARNING_RATE = 5e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LTAApk0GOdnn"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(\n",
    "    filter(lambda p: p.requires_grad, tfidf_model.parameters()),\n",
    "    lr=LEARNING_RATE,\n",
    ")\n",
    "scheduler = CosineAnnealingLR(optimizer, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 5001
    },
    "colab_type": "code",
    "id": "JOKbMYOaQR8-",
    "outputId": "32ea4623-4fef-4ffd-e6e6-0a82d4c11723"
   },
   "outputs": [],
   "source": [
    "n_epochs = 0\n",
    "train_losses, valid_losses = [], []\n",
    "while True:\n",
    "    train_loss = train_epoch(tfidf_model, optimizer, train_loader, input_type='tfidf')\n",
    "    valid_loss = validate_epoch(tfidf_model, valid_loader, input_type='tfidf')\n",
    "    \n",
    "    tqdm.write(\n",
    "        f'epoch #{n_epochs + 1:3d}\\ttrain_loss: {train_loss:.2e}\\tvalid_loss: {valid_loss:.2e}\\n',\n",
    "    )\n",
    "    \n",
    "    # Early stopping if the current valid_loss is greater than the last three valid losses\n",
    "    if len(valid_losses) > 2 and all(valid_loss >= loss for loss in valid_losses[-3:]):\n",
    "        print('Stopping early')\n",
    "        break\n",
    "    \n",
    "    train_losses.append(train_loss)\n",
    "    valid_losses.append(valid_loss)\n",
    "    \n",
    "    n_epochs += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 396
    },
    "colab_type": "code",
    "id": "DwjtRORzZzjG",
    "outputId": "220ecdca-4105-4307-a070-21a41f50bf73"
   },
   "outputs": [],
   "source": [
    "epoch_ticks = range(1, n_epochs + 1)\n",
    "plt.plot(epoch_ticks, train_losses)\n",
    "plt.plot(epoch_ticks, valid_losses)\n",
    "plt.legend(['Train Loss', 'Valid Loss'])\n",
    "plt.title('Losses') \n",
    "plt.xlabel('Epoch #')\n",
    "plt.ylabel('Loss')\n",
    "plt.xticks(epoch_ticks)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jb3JqkXJQR9B"
   },
   "source": [
    "### TF-IDF Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "CD7f_FdEQR9B",
    "outputId": "1c9cd42c-953d-4548-c1cf-f5b67d9edc26"
   },
   "outputs": [],
   "source": [
    "tfidf_model.eval()\n",
    "test_accuracy, n_examples = 0, 0\n",
    "y_true, y_pred = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for seq, bow, tfidf, target, text in test_loader:\n",
    "        inputs = tfidf\n",
    "        probs = tfidf_model(inputs)\n",
    "        \n",
    "        probs = probs.detach().cpu().numpy()\n",
    "        predictions = np.argmax(probs, axis=1)\n",
    "        target = target.cpu().numpy()\n",
    "        \n",
    "        y_true.extend(predictions)\n",
    "        y_pred.extend(target)\n",
    "        \n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 686
    },
    "colab_type": "code",
    "id": "iBp1TrcnQR9E",
    "outputId": "759118e0-909e-431f-b419-9b838b2b3db4"
   },
   "outputs": [],
   "source": [
    "print_random_prediction(tfidf_model, n=5, input_type='tfidf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "17mRlwN2QWUj"
   },
   "source": [
    "## Exercise: Build your own Logistic Regression Text Classifier\n",
    "\n",
    "\n",
    "- Input: BoW vector or TF-IDF vector\n",
    "- 1 Affine layer (what are the dimensions of input and output?)\n",
    "- 1 Sigmoid activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OfKe8uzUQfdJ"
   },
   "outputs": [],
   "source": [
    "## define your affine layer dimension here:\n",
    "\n",
    "\n",
    "class LogisticRegressionClassifier(nn.Module):\n",
    "    def __init__(self, device, batch_size, ): # pass layer dimension \n",
    "        self.device = device\n",
    "        ## add affine layer\n",
    "        \n",
    "    def forward(self, x):\n",
    "        batch_size = len(x)\n",
    "        if batch_size != self.batch_size:\n",
    "            self.batch_size = batch_size\n",
    "        ## pass through affine layer & activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JyvgjZ66WrXs"
   },
   "outputs": [],
   "source": [
    "lr_model = LogisticRegressionClassifier(\n",
    "    ## your code here\n",
    "    ##\n",
    "    device=device,\n",
    "    batch_size=BATCH_SIZE,\n",
    ")\n",
    "lr_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZBnDTmr5XJGJ"
   },
   "outputs": [],
   "source": [
    "LEARNING_RATE = ## give your number\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(\n",
    "    filter(lambda p: p.requires_grad, lr_model.parameters()),\n",
    "    lr=LEARNING_RATE,\n",
    ")\n",
    "scheduler = CosineAnnealingLR(optimizer, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KOaGLcA6Xa-A"
   },
   "outputs": [],
   "source": [
    "## Run training & validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w8Vagiy9aK_G"
   },
   "outputs": [],
   "source": [
    "epoch_ticks = range(1, n_epochs + 1)\n",
    "plt.plot(epoch_ticks, train_losses)\n",
    "plt.plot(epoch_ticks, valid_losses)\n",
    "plt.legend(['Train Loss', 'Valid Loss'])\n",
    "plt.title('Losses') \n",
    "plt.xlabel('Epoch #')\n",
    "plt.ylabel('Loss')\n",
    "plt.xticks(epoch_ticks)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KYBQdpqsaL32"
   },
   "outputs": [],
   "source": [
    "## Run model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-Z9WfZzfXd30"
   },
   "outputs": [],
   "source": [
    "print_random_prediction(tfidf_model, n=5, input_type='tfidf')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "1_BoW_text_classification.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
